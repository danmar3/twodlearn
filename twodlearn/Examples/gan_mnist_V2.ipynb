{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Nets on MNIST\n",
    "\n",
    "Created by: Daniel L. Marino (marinodl@vcu.edu)\n",
    "\n",
    "Description: Implementation of the algorithm shown in Goodfellow et al. \"Generative Adversarial Nets\" (https://arxiv.org/pdf/1406.2661v1.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from twodlearn.feedforward import *\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(100, 784)\n",
      "(100, 28, 28, 1)\n",
      "(100, 10)\n",
      "1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "batch_X, batch_y = mnist.train.next_batch(100)\n",
    "\n",
    "print(batch_X.shape)\n",
    "print(np.reshape(batch_X, [-1,28,28,1]).shape)\n",
    "print(batch_y.shape)\n",
    "print(np.max(batch_X), np.min(batch_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth=True\n",
    "\n",
    "sess = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_size = batch_X.shape[-1];\n",
    "z_size = 100\n",
    "d_hidden = [240, 240]\n",
    "\n",
    "# Define MLP Net\n",
    "d_net= MlpNet( x_size, 1, d_hidden, afunction= tf.nn.relu ,name='DNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_hidden = [1000, 1000]\n",
    "\n",
    "# Define MLP Net\n",
    "g_net= MlpNet( z_size, x_size, g_hidden, afunction= tf.nn.relu ,name='GNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nvarlist = tf.trainable_variables()\\n\\nprint(len(varlist))\\nprint(varlist[0].name )\\nprint(varlist[1].name )\\nprint('GNet' in varlist[1].name )\\n\\ng_trainable = [ w for w in tf.trainable_variables() if 'GNet' in w.name]\\nprint(len(g_trainable))\\n\\nprint(g_trainable[0].name)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "varlist = tf.trainable_variables()\n",
    "\n",
    "print(len(varlist))\n",
    "print(varlist[0].name )\n",
    "print(varlist[1].name )\n",
    "print('GNet' in varlist[1].name )\n",
    "\n",
    "g_trainable = [ w for w in tf.trainable_variables() if 'GNet' in w.name]\n",
    "print(len(g_trainable))\n",
    "\n",
    "print(g_trainable[0].name)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 600;\n",
    "batch_size_traing = m;\n",
    "batch_size_traind = 2*m;\n",
    "\n",
    "drop_prob_d = tf.placeholder(tf.float32)\n",
    "drop_prob_g = tf.placeholder(tf.float32)\n",
    "\n",
    "''' 1. For the discriminative loss '''\n",
    "g_traind = g_net.setup( m );\n",
    "d_traind = d_net.setup( batch_size_traind, drop_prob_d, loss_type= 'cross_entropy' );\n",
    "\n",
    "traind_loss = d_traind.loss;\n",
    "# Optimizer.\n",
    "d_trainable = [ w for w in tf.trainable_variables() if 'DNet' in w.name]\n",
    "\n",
    "\n",
    "#d_opt = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "d_opt = tf.train.MomentumOptimizer(learning_rate=0.1, momentum= 0.5)\n",
    "d_optimizer = d_opt.minimize(traind_loss, var_list= d_trainable)\n",
    "#d_optimizer = tf.train.AdamOptimizer(0.0005).minimize(dtrain_loss, var_list = d_trainable) #0.001\n",
    "\n",
    "''' 2. For the generative loss '''\n",
    "g_traing = g_net.setup(batch_size_traing);\n",
    "d_traing = d_net.setup(batch_size_traing, drop_prob_d, inputs= tf.sigmoid(g_traing.y), loss_type= 'cross_entropy');\n",
    "\n",
    "traing_loss = d_traing.loss;\n",
    "\n",
    "# Optimizer.\n",
    "g_trainable = [ w for w in tf.trainable_variables() if 'GNet' in w.name]\n",
    "\n",
    "#g_opt = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "g_opt = tf.train.MomentumOptimizer(learning_rate=0.1, momentum= 0.5)\n",
    "g_optimizer = g_opt.minimize(traing_loss, var_list= g_trainable)\n",
    "\n",
    "# for generating data\n",
    "gen_model = tf.sigmoid(g_traind.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_generator(n_samples, n_dim):\n",
    "    return 2.0*(np.random.rand(n_samples, n_dim) - 0.5)\n",
    "\n",
    "def data_generator(n_samples, noise_p= None):\n",
    "    batch_x, _= mnist.train.next_batch(n_samples) # images values are normalized between 0-1\n",
    "    \n",
    "    if noise_p is None:\n",
    "        return batch_x\n",
    "        \n",
    "    else:\n",
    "        rand_x = np.random.rand(*batch_x.shape) # random noise values are between 0-1\n",
    "        \n",
    "        return (1-noise_p)*batch_x + noise_p*rand_x;\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "0  | d_loss: 0.00695377528667  | g_loss: 0.00709514975548  | noise_p: 0.8\n",
      "100  | d_loss: 0.638210971951  | g_loss: 0.904740842581  | noise_p: 0.7920398669993345\n",
      "200  | d_loss: 0.665301110744  | g_loss: 0.774001003504  | noise_p: 0.7841589386454042\n",
      "300  | d_loss: 0.665672712326  | g_loss: 0.762062779665  | noise_p: 0.7763564268388066\n",
      "400  | d_loss: 0.72319217205  | g_loss: 0.605882829428  | noise_p: 0.7686315513218586\n",
      "500  | d_loss: 0.673400421143  | g_loss: 0.661391592324  | noise_p: 0.7609835396005713\n",
      "600  | d_loss: 0.689746076465  | g_loss: 0.7065415591  | noise_p: 0.753411626867399\n",
      "700  | d_loss: 0.688051847816  | g_loss: 0.71624822557  | noise_p: 0.7459150559247587\n",
      "800  | d_loss: 0.67925362885  | g_loss: 0.724460701346  | noise_p: 0.7384930771093087\n",
      "900  | d_loss: 0.670691596866  | g_loss: 0.725115529895  | noise_p: 0.7311449482169826\n",
      "1000  | d_loss: 0.673077796102  | g_loss: 0.748216623962  | noise_p: 0.7238699344287677\n",
      "1100  | d_loss: 0.664562705159  | g_loss: 0.770218914151  | noise_p: 0.7166673082372226\n",
      "1200  | d_loss: 0.655690004826  | g_loss: 0.774120182395  | noise_p: 0.709536349373726\n",
      "1300  | d_loss: 0.659497824311  | g_loss: 0.786745709777  | noise_p: 0.702476344736449\n",
      "1400  | d_loss: 0.663418764472  | g_loss: 0.746501081586  | noise_p: 0.6954865883190448\n",
      "1500  | d_loss: 0.671223301291  | g_loss: 0.802619068623  | noise_p: 0.6885663811400463\n",
      "1600  | d_loss: 0.687026113272  | g_loss: 0.755184051394  | noise_p: 0.6817150311729692\n",
      "1700  | d_loss: 0.675047783852  | g_loss: 0.726433725059  | noise_p: 0.674931853277107\n",
      "1800  | d_loss: 0.661925709248  | g_loss: 0.756955606937  | noise_p: 0.6682161691290176\n",
      "1900  | d_loss: 0.669953646064  | g_loss: 0.764982862473  | noise_p: 0.6615673071546899\n",
      "2000  | d_loss: 0.672184445262  | g_loss: 0.738074863851  | noise_p: 0.6549846024623855\n",
      "2100  | d_loss: 0.68354439199  | g_loss: 0.710754172206  | noise_p: 0.6484673967761497\n",
      "2200  | d_loss: 0.681494295001  | g_loss: 0.733441689014  | noise_p: 0.6420150383699829\n",
      "2300  | d_loss: 0.660662361979  | g_loss: 0.749011126757  | noise_p: 0.6356268820026673\n",
      "2400  | d_loss: 0.670610870123  | g_loss: 0.761147043705  | noise_p: 0.6293022888532427\n",
      "2500  | d_loss: 0.665649185777  | g_loss: 0.758734584749  | noise_p: 0.623040626457124\n",
      "2600  | d_loss: 0.67850207448  | g_loss: 0.730167514682  | noise_p: 0.616841268642853\n",
      "2700  | d_loss: 0.658884117007  | g_loss: 0.781105591655  | noise_p: 0.6107035954694826\n",
      "2800  | d_loss: 0.691410578489  | g_loss: 0.750896708369  | noise_p: 0.6046269931645805\n",
      "2900  | d_loss: 0.669323474765  | g_loss: 0.742766263485  | noise_p: 0.5986108540628522\n",
      "3000  | d_loss: 0.678128820062  | g_loss: 0.739207634926  | noise_p: 0.5926545765453743\n",
      "3100  | d_loss: 0.684335603714  | g_loss: 0.714553375244  | noise_p: 0.5867575649794314\n",
      "3200  | d_loss: 0.683777419329  | g_loss: 0.703809454441  | noise_p: 0.5809192296589528\n",
      "3300  | d_loss: 0.690872842073  | g_loss: 0.698248650432  | noise_p: 0.575138986745541\n",
      "3400  | d_loss: 0.688932831883  | g_loss: 0.701800627708  | noise_p: 0.5694162582100878\n",
      "3500  | d_loss: 0.688401609063  | g_loss: 0.698976701498  | noise_p: 0.5637504717749707\n",
      "3600  | d_loss: 0.684153573513  | g_loss: 0.708267450333  | noise_p: 0.5581410608568248\n",
      "3700  | d_loss: 0.680976679921  | g_loss: 0.711315448284  | noise_p: 0.5525874645098837\n",
      "3800  | d_loss: 0.678390197158  | g_loss: 0.710724132657  | noise_p: 0.5470891273698847\n",
      "3900  | d_loss: 0.673970271945  | g_loss: 0.720129272342  | noise_p: 0.5416454995985317\n",
      "4000  | d_loss: 0.676051918864  | g_loss: 0.718524719477  | noise_p: 0.5362560368285115\n",
      "4100  | d_loss: 0.679445149899  | g_loss: 0.743118612468  | noise_p: 0.5309202001090555\n",
      "4200  | d_loss: 0.67406547606  | g_loss: 0.786528567076  | noise_p: 0.5256374558520455\n",
      "4300  | d_loss: 0.658313909173  | g_loss: 0.755570843667  | noise_p: 0.5204072757786532\n",
      "4400  | d_loss: 0.600069382787  | g_loss: 0.957010848522  | noise_p: 0.5152291368665132\n",
      "4500  | d_loss: 0.615427063107  | g_loss: 0.893382799923  | noise_p: 0.5101025212974187\n",
      "4600  | d_loss: 0.612935928106  | g_loss: 0.856653510332  | noise_p: 0.5050269164055408\n",
      "4700  | d_loss: 0.645579826236  | g_loss: 0.841194317937  | noise_p: 0.5000018146261607\n",
      "4800  | d_loss: 0.637955036461  | g_loss: 0.852143803164  | noise_p: 0.49502671344491267\n",
      "4900  | d_loss: 0.648774200678  | g_loss: 0.813600474  | noise_p: 0.4901011153475328\n",
      "5000  | d_loss: 0.669456667304  | g_loss: 0.771023324728  | noise_p: 0.4852245277701068\n",
      "5100  | d_loss: 0.693208034039  | g_loss: 0.69298224926  | noise_p: 0.48039646304981276\n",
      "5200  | d_loss: 0.692618703842  | g_loss: 0.69639365077  | noise_p: 0.4756164383761555\n",
      "5300  | d_loss: 0.688772898316  | g_loss: 0.69856582433  | noise_p: 0.47088397574268415\n",
      "5400  | d_loss: 0.686162936091  | g_loss: 0.730591091514  | noise_p: 0.4661986018991917\n",
      "5500  | d_loss: 0.692218913436  | g_loss: 0.69830701977  | noise_p: 0.46155984830438934\n",
      "5600  | d_loss: 0.688592997193  | g_loss: 0.705285900831  | noise_p: 0.4569672510790519\n",
      "5700  | d_loss: 0.693261683583  | g_loss: 0.693249419928  | noise_p: 0.4524203509596297\n",
      "5800  | d_loss: 0.692852771282  | g_loss: 0.69318987608  | noise_p: 0.44791869325232164\n",
      "5900  | d_loss: 0.687617180347  | g_loss: 0.703224831223  | noise_p: 0.4434618277876056\n",
      "6000  | d_loss: 0.685959875584  | g_loss: 0.708479000032  | noise_p: 0.43904930887522114\n",
      "6100  | d_loss: 0.678872749209  | g_loss: 0.743327786028  | noise_p: 0.43468069525959985\n",
      "6200  | d_loss: 0.65951975286  | g_loss: 0.789797012806  | noise_p: 0.4303555500757396\n",
      "6300  | d_loss: 0.679770058692  | g_loss: 0.720374076962  | noise_p: 0.4260734408055178\n",
      "6400  | d_loss: 0.614672446549  | g_loss: 0.938571619987  | noise_p: 0.42183393923443885\n",
      "6500  | d_loss: 0.680076109767  | g_loss: 0.752690252662  | noise_p: 0.41763662140881286\n",
      "6600  | d_loss: 0.690590416193  | g_loss: 0.71114309296  | noise_p: 0.41348106759335934\n",
      "6700  | d_loss: 0.692935211658  | g_loss: 0.694072835445  | noise_p: 0.40936686222923396\n",
      "6800  | d_loss: 0.682056316137  | g_loss: 0.725935821235  | noise_p: 0.40529359389247166\n",
      "6900  | d_loss: 0.679460267425  | g_loss: 0.731819805503  | noise_p: 0.4012608552528444\n",
      "7000  | d_loss: 0.688687825799  | g_loss: 0.710839491487  | noise_p: 0.3972682430331276\n",
      "7100  | d_loss: 0.681040235162  | g_loss: 0.715505903959  | noise_p: 0.39331535796877204\n",
      "7200  | d_loss: 0.68833814919  | g_loss: 0.708359789848  | noise_p: 0.3894018047679773\n",
      "7300  | d_loss: 0.687332023978  | g_loss: 0.710682391822  | noise_p: 0.38552719207216196\n",
      "7400  | d_loss: 0.687666264772  | g_loss: 0.708351782858  | noise_p: 0.3816911324168275\n",
      "7500  | d_loss: 0.690594257712  | g_loss: 0.698166182041  | noise_p: 0.3778932421928118\n",
      "7600  | d_loss: 0.689541925788  | g_loss: 0.701691281199  | noise_p: 0.37413314160792743\n",
      "7700  | d_loss: 0.685161260366  | g_loss: 0.711537012756  | noise_p: 0.3704104546489825\n",
      "7800  | d_loss: 0.679294320345  | g_loss: 0.725269359946  | noise_p: 0.3667248090441788\n",
      "7900  | d_loss: 0.68691204071  | g_loss: 0.719462096393  | noise_p: 0.3630758362258847\n",
      "8000  | d_loss: 0.679000875354  | g_loss: 0.726647583246  | noise_p: 0.35946317129377725\n",
      "8100  | d_loss: 0.677342991829  | g_loss: 0.731222882271  | noise_p: 0.3558864529783529\n",
      "8200  | d_loss: 0.656229520738  | g_loss: 0.781631135345  | noise_p: 0.3523453236047994\n",
      "8300  | d_loss: 0.675909672379  | g_loss: 0.737158877254  | noise_p: 0.3488394290572285\n",
      "8400  | d_loss: 0.687306346893  | g_loss: 0.717020811588  | noise_p: 0.34536841874326374\n",
      "8500  | d_loss: 0.63566044271  | g_loss: 0.997090320289  | noise_p: 0.3419319455589813\n",
      "8600  | d_loss: 0.642060795724  | g_loss: 0.86153444916  | noise_p: 0.3385296658541991\n",
      "8700  | d_loss: 0.647510836124  | g_loss: 0.802788287401  | noise_p: 0.3351612393981112\n",
      "8800  | d_loss: 0.628863006234  | g_loss: 0.902883333564  | noise_p: 0.3318263293452651\n",
      "8900  | d_loss: 0.639209808111  | g_loss: 0.851873414516  | noise_p: 0.3285246022018764\n",
      "9000  | d_loss: 0.586337276399  | g_loss: 1.03467468262  | noise_p: 0.3252557277924793\n",
      "9100  | d_loss: 0.561785785854  | g_loss: 1.06695031404  | noise_p: 0.3220193792269088\n",
      "9200  | d_loss: 0.577062579393  | g_loss: 1.06432033837  | noise_p: 0.3188152328676113\n",
      "9300  | d_loss: 0.507678498924  | g_loss: 1.31123277664  | noise_p: 0.3156429682972809\n",
      "9400  | d_loss: 0.513857326508  | g_loss: 1.30649597555  | noise_p: 0.3125022682868169\n",
      "9500  | d_loss: 0.603200165927  | g_loss: 1.54072507551  | noise_p: 0.309392818763601\n",
      "9600  | d_loss: 0.524405402243  | g_loss: 1.16186594844  | noise_p: 0.30631430878008964\n",
      "9700  | d_loss: 0.549700953066  | g_loss: 1.38005334556  | noise_p: 0.30326643048271906\n",
      "9800  | d_loss: 0.542673265934  | g_loss: 1.3299705261  | noise_p: 0.30024887908111964\n",
      "9900  | d_loss: 0.534196604788  | g_loss: 1.27928884149  | noise_p: 0.29726135281763655\n",
      "10000  | d_loss: 0.553355604112  | g_loss: 1.10909871995  | noise_p: 0.2943035529371539\n",
      "10100  | d_loss: 0.600700247586  | g_loss: 1.19554957852  | noise_p: 0.29137518365721865\n",
      "10200  | d_loss: 0.571885703802  | g_loss: 1.12222762346  | noise_p: 0.28847595213846267\n",
      "10300  | d_loss: 0.567796062529  | g_loss: 1.03728932619  | noise_p: 0.2856055684553179\n",
      "10400  | d_loss: 0.55467220813  | g_loss: 1.16127749979  | noise_p: 0.28276374556702416\n",
      "10500  | d_loss: 0.572154591084  | g_loss: 1.08181626946  | noise_p: 0.2799501992889243\n",
      "10600  | d_loss: 0.566670164764  | g_loss: 1.13601125509  | noise_p: 0.2771646482640459\n",
      "10700  | d_loss: 0.522405049205  | g_loss: 1.24270971477  | noise_p: 0.2744068139349653\n",
      "10800  | d_loss: 0.516661869287  | g_loss: 1.26915170789  | noise_p: 0.2716764205159513\n",
      "10900  | d_loss: 0.534344561696  | g_loss: 1.44684334368  | noise_p: 0.2689731949653867\n",
      "11000  | d_loss: 0.525762342215  | g_loss: 1.21115853965  | noise_p: 0.26629686695846366\n",
      "11100  | d_loss: 0.546659193635  | g_loss: 1.30784274697  | noise_p: 0.26364716886015127\n",
      "11200  | d_loss: 0.508813489676  | g_loss: 1.22928487837  | noise_p: 0.26102383569843157\n",
      "11300  | d_loss: 0.51480635792  | g_loss: 1.2820637548  | noise_p: 0.2584266051378023\n",
      "11400  | d_loss: 0.548989211917  | g_loss: 1.4387535125  | noise_p: 0.25585521745304307\n",
      "11500  | d_loss: 0.522100322545  | g_loss: 1.40024990618  | noise_p: 0.25330941550324254\n",
      "11600  | d_loss: 0.505702233016  | g_loss: 1.31284886658  | noise_p: 0.2507889447060842\n",
      "11700  | d_loss: 0.507752435505  | g_loss: 1.48306405187  | noise_p: 0.24829355301238798\n",
      "11800  | d_loss: 0.480992317796  | g_loss: 1.55864768744  | noise_p: 0.24582299088090498\n",
      "11900  | d_loss: 0.486686977744  | g_loss: 1.37291558087  | noise_p: 0.24337701125336328\n",
      "12000  | d_loss: 0.511631240249  | g_loss: 1.57975888252  | noise_p: 0.2409553695297617\n",
      "12100  | d_loss: 0.4971841681  | g_loss: 1.4994272238  | noise_p: 0.23855782354390992\n",
      "12200  | d_loss: 0.516230649054  | g_loss: 1.41509881765  | noise_p: 0.2361841335392114\n",
      "12300  | d_loss: 0.518411281109  | g_loss: 1.61295929313  | noise_p: 0.23383406214468755\n",
      "12400  | d_loss: 0.5103860268  | g_loss: 1.53395123541  | noise_p: 0.2315073743512405\n",
      "12500  | d_loss: 0.550080271661  | g_loss: 1.48225041121  | noise_p: 0.2292038374881521\n",
      "12600  | d_loss: 0.486691273749  | g_loss: 1.43426996469  | noise_p: 0.22692322119981634\n",
      "12700  | d_loss: 0.516215032637  | g_loss: 1.48374827325  | noise_p: 0.22466529742270383\n",
      "12800  | d_loss: 0.488853037357  | g_loss: 1.54045772135  | noise_p: 0.2224298403625553\n",
      "12900  | d_loss: 0.543619405925  | g_loss: 1.28115671277  | noise_p: 0.22021662647180187\n",
      "13000  | d_loss: 0.526324755251  | g_loss: 1.24917793036  | noise_p: 0.2180254344272101\n",
      "13100  | d_loss: 0.527689036429  | g_loss: 1.2773134023  | noise_p: 0.21585604510774947\n",
      "13200  | d_loss: 0.486329661012  | g_loss: 1.47231133819  | noise_p: 0.21370824157268029\n",
      "13300  | d_loss: 0.502055101097  | g_loss: 1.41089592814  | noise_p: 0.21158180903985918\n",
      "13400  | d_loss: 0.496004964411  | g_loss: 1.4051968348  | noise_p: 0.2094765348642608\n",
      "13500  | d_loss: 0.505422539115  | g_loss: 1.40081534624  | noise_p: 0.20739220851671322\n",
      "13600  | d_loss: 0.488773674965  | g_loss: 1.496075477  | noise_p: 0.2053286215628447\n",
      "13700  | d_loss: 0.481142503917  | g_loss: 1.37661718607  | noise_p: 0.20328556764224023\n",
      "13800  | d_loss: 0.488339283466  | g_loss: 1.49110315427  | noise_p: 0.20126284244780518\n",
      "13900  | d_loss: 0.448474286199  | g_loss: 1.43152703285  | noise_p: 0.19926024370533454\n",
      "14000  | d_loss: 0.463012264073  | g_loss: 1.53396344423  | noise_p: 0.19727757115328515\n",
      "14100  | d_loss: 0.438882009089  | g_loss: 1.70308209777  | noise_p: 0.19531462652274967\n",
      "14200  | d_loss: 0.447705430686  | g_loss: 1.65285454571  | noise_p: 0.19337121351762915\n",
      "14300  | d_loss: 0.445246265233  | g_loss: 1.74569265097  | noise_p: 0.1914471377950036\n",
      "14400  | d_loss: 0.434747252464  | g_loss: 1.73953474462  | noise_p: 0.18954220694569737\n",
      "14500  | d_loss: 0.464731941819  | g_loss: 1.63990194738  | noise_p: 0.1876562304750381\n",
      "14600  | d_loss: 0.409699821174  | g_loss: 1.7853548038  | noise_p: 0.18578901978380707\n",
      "14700  | d_loss: 0.489042387903  | g_loss: 1.74009883426  | noise_p: 0.18394038814937907\n",
      "14800  | d_loss: 0.47150726378  | g_loss: 1.57110552669  | noise_p: 0.1821101507070502\n",
      "14900  | d_loss: 0.454098938704  | g_loss: 1.6163180089  | noise_p: 0.180298124431551\n",
      "15000  | d_loss: 0.477522341013  | g_loss: 1.50941774845  | noise_p: 0.17850412811874386\n",
      "15100  | d_loss: 0.464781232774  | g_loss: 1.50475387633  | noise_p: 0.17672798236750256\n",
      "15200  | d_loss: 0.470524308383  | g_loss: 1.71374032795  | noise_p: 0.17496950956177182\n",
      "15300  | d_loss: 0.482221772075  | g_loss: 1.58585436702  | noise_p: 0.17322853385280568\n",
      "15400  | d_loss: 0.469258666337  | g_loss: 1.66657120883  | noise_p: 0.17150488114158235\n",
      "15500  | d_loss: 0.459060083032  | g_loss: 1.59250960588  | noise_p: 0.16979837906139444\n",
      "15600  | d_loss: 0.481384219825  | g_loss: 1.61136313975  | noise_p: 0.16810885696061179\n",
      "15700  | d_loss: 0.492391501665  | g_loss: 1.50150194705  | noise_p: 0.1664361458856164\n",
      "15800  | d_loss: 0.471123212576  | g_loss: 1.49558238268  | noise_p: 0.16478007856390675\n",
      "15900  | d_loss: 0.473081368506  | g_loss: 1.64105416775  | noise_p: 0.16314048938737075\n",
      "16000  | d_loss: 0.456180414557  | g_loss: 1.64151144981  | noise_p: 0.1615172143957243\n",
      "16100  | d_loss: 0.482942329347  | g_loss: 1.51125403762  | noise_p: 0.1599100912601156\n",
      "16200  | d_loss: 0.500625928938  | g_loss: 1.3649818182  | noise_p: 0.15831895926689174\n",
      "16300  | d_loss: 0.49411223352  | g_loss: 1.40316998482  | noise_p: 0.15674365930152748\n",
      "16400  | d_loss: 0.49841681242  | g_loss: 1.41754348278  | noise_p: 0.1551840338327135\n",
      "16500  | d_loss: 0.489308845103  | g_loss: 1.43503450036  | noise_p: 0.15363992689660327\n",
      "16600  | d_loss: 0.47099182874  | g_loss: 1.65050599217  | noise_p: 0.1521111840812164\n",
      "16700  | d_loss: 0.484012685418  | g_loss: 1.53008591413  | noise_p: 0.1505976525109974\n",
      "16800  | d_loss: 0.476874910593  | g_loss: 1.44246942043  | noise_p: 0.14909918083152796\n",
      "16900  | d_loss: 0.486870845556  | g_loss: 1.52717354655  | noise_p: 0.1476156191943914\n",
      "17000  | d_loss: 0.502783673406  | g_loss: 1.48572473526  | noise_p: 0.1461468192421877\n",
      "17100  | d_loss: 0.490010730922  | g_loss: 1.50639374971  | noise_p: 0.14469263409369765\n",
      "17200  | d_loss: 0.476899885833  | g_loss: 1.60000606179  | noise_p: 0.1432529183291946\n",
      "17300  | d_loss: 0.471423717737  | g_loss: 1.52583185315  | noise_p: 0.14182752797590226\n",
      "17400  | d_loss: 0.47799048245  | g_loss: 1.5112012434  | noise_p: 0.1404163204935975\n",
      "17500  | d_loss: 0.484042842686  | g_loss: 1.52395416021  | noise_p: 0.13901915476035612\n",
      "17600  | d_loss: 0.487194575965  | g_loss: 1.48411681652  | noise_p: 0.13763589105844043\n",
      "17700  | d_loss: 0.478751198947  | g_loss: 1.51767580569  | noise_p: 0.13626639106032754\n",
      "17800  | d_loss: 0.467931987941  | g_loss: 1.58588457704  | noise_p: 0.1349105178148764\n",
      "17900  | d_loss: 0.469303959608  | g_loss: 1.56077617407  | noise_p: 0.13356813573363255\n",
      "18000  | d_loss: 0.474519404769  | g_loss: 1.61313520551  | noise_p: 0.13223911057726923\n",
      "18100  | d_loss: 0.47017406255  | g_loss: 1.51768686891  | noise_p: 0.13092330944216324\n",
      "18200  | d_loss: 0.471964204311  | g_loss: 1.49660390854  | noise_p: 0.1296206007471046\n",
      "18300  | d_loss: 0.463625847697  | g_loss: 1.63409507215  | noise_p: 0.1283308542201382\n",
      "18400  | d_loss: 0.468150573671  | g_loss: 1.62914677858  | noise_p: 0.12705394088553654\n",
      "18500  | d_loss: 0.481496227086  | g_loss: 1.62579625309  | noise_p: 0.1257897330509021\n",
      "18600  | d_loss: 0.480588102937  | g_loss: 1.52564590693  | noise_p: 0.12453810429439785\n",
      "18700  | d_loss: 0.492890680432  | g_loss: 1.51101630807  | noise_p: 0.12329892945210513\n",
      "18800  | d_loss: 0.497693845034  | g_loss: 1.47875756264  | noise_p: 0.1220720846055071\n",
      "18900  | d_loss: 0.489587022066  | g_loss: 1.45194549441  | noise_p: 0.12085744706909668\n",
      "19000  | d_loss: 0.48746804893  | g_loss: 1.42675890207  | noise_p: 0.11965489537810803\n",
      "19100  | d_loss: 0.477354137003  | g_loss: 1.4251489234  | noise_p: 0.11846430927636996\n",
      "19200  | d_loss: 0.49111910522  | g_loss: 1.41078987837  | noise_p: 0.11728556970428011\n",
      "19300  | d_loss: 0.496668246984  | g_loss: 1.45399875402  | noise_p: 0.11611855878689897\n",
      "19400  | d_loss: 0.491624296606  | g_loss: 1.47613373399  | noise_p: 0.11496315982216232\n",
      "19500  | d_loss: 0.486313941181  | g_loss: 1.47086198211  | noise_p: 0.11381925726921083\n",
      "19600  | d_loss: 0.47663226366  | g_loss: 1.51494667828  | noise_p: 0.11268673673683599\n",
      "19700  | d_loss: 0.492263724208  | g_loss: 1.4241130805  | noise_p: 0.11156548497204073\n",
      "19800  | d_loss: 0.485230249763  | g_loss: 1.43516684592  | noise_p: 0.11045538984871424\n",
      "19900  | d_loss: 0.496255120039  | g_loss: 1.40577559471  | noise_p: 0.10935634035641909\n",
      "20000  | d_loss: 0.483439293504  | g_loss: 1.42322739124  | noise_p: 0.10826822658929017\n",
      "20100  | d_loss: 0.490587770343  | g_loss: 1.50933394492  | noise_p: 0.10719093973504396\n",
      "20200  | d_loss: 0.45756088227  | g_loss: 1.48666882396  | noise_p: 0.10612437206409737\n",
      "20300  | d_loss: 0.455506362021  | g_loss: 1.56640164554  | noise_p: 0.10506841691879443\n",
      "20400  | d_loss: 0.465252490342  | g_loss: 1.53687976599  | noise_p: 0.10402296870274073\n",
      "20500  | d_loss: 0.467403558195  | g_loss: 1.5874380213  | noise_p: 0.10298792287024335\n",
      "20600  | d_loss: 0.469431438446  | g_loss: 1.55528146744  | noise_p: 0.1019631759158566\n",
      "20700  | d_loss: 0.471555146575  | g_loss: 1.5326346755  | noise_p: 0.10094862536403099\n",
      "20800  | d_loss: 0.459745266438  | g_loss: 1.56138796568  | noise_p: 0.09994416975886594\n",
      "20900  | d_loss: 0.465006011724  | g_loss: 1.61890893996  | noise_p: 0.09894970865396382\n",
      "21000  | d_loss: 0.460175805688  | g_loss: 1.54751325607  | noise_p: 0.09796514260238554\n",
      "21100  | d_loss: 0.454256524742  | g_loss: 1.55149734795  | noise_p: 0.0969903731467053\n",
      "21200  | d_loss: 0.478391804993  | g_loss: 1.62643052518  | noise_p: 0.09602530280916538\n",
      "21300  | d_loss: 0.4583863464  | g_loss: 1.6220615983  | noise_p: 0.09506983508192773\n",
      "21400  | d_loss: 0.468792566657  | g_loss: 1.57198422551  | noise_p: 0.09412387441742336\n",
      "21500  | d_loss: 0.456842893958  | g_loss: 1.6292229259  | noise_p: 0.09318732621879758\n",
      "21600  | d_loss: 0.454443835616  | g_loss: 1.56136811137  | noise_p: 0.09226009683045001\n",
      "21700  | d_loss: 0.450336949229  | g_loss: 1.6062717545  | noise_p: 0.0913420935286692\n",
      "21800  | d_loss: 0.461886412203  | g_loss: 1.59565851688  | noise_p: 0.09043322451235988\n",
      "21900  | d_loss: 0.452852782011  | g_loss: 1.60817310572  | noise_p: 0.08953339889386311\n",
      "22000  | d_loss: 0.453051773906  | g_loss: 1.65634195924  | noise_p: 0.08864252668986711\n",
      "22100  | d_loss: 0.461040270627  | g_loss: 1.6644245553  | noise_p: 0.08776051881240914\n",
      "22200  | d_loss: 0.447970228493  | g_loss: 1.61195048928  | noise_p: 0.08688728705996637\n",
      "22300  | d_loss: 0.447414467633  | g_loss: 1.66061554909  | noise_p: 0.08602274410863597\n",
      "22400  | d_loss: 0.44666844964  | g_loss: 1.64375985026  | noise_p: 0.08516680350340225\n",
      "22500  | d_loss: 0.441348280311  | g_loss: 1.707343449  | noise_p: 0.08431937964949147\n",
      "22600  | d_loss: 0.454669265747  | g_loss: 1.65854594469  | noise_p: 0.083480387803812\n",
      "22700  | d_loss: 0.453086079955  | g_loss: 1.60359513521  | noise_p: 0.08264974406648017\n",
      "22800  | d_loss: 0.444099604487  | g_loss: 1.65461405993  | noise_p: 0.08182736537242996\n",
      "22900  | d_loss: 0.439076958895  | g_loss: 1.69409752369  | noise_p: 0.08101316948310672\n",
      "23000  | d_loss: 0.448473607898  | g_loss: 1.69373803496  | noise_p: 0.08020707497824298\n",
      "23100  | d_loss: 0.447888861299  | g_loss: 1.71046977162  | noise_p: 0.07940900124771653\n",
      "23200  | d_loss: 0.440289563537  | g_loss: 1.67058806896  | noise_p: 0.0786188684834892\n",
      "23300  | d_loss: 0.435205988586  | g_loss: 1.76424214602  | noise_p: 0.0778365976716262\n",
      "23400  | d_loss: 0.442615087032  | g_loss: 1.68787311316  | noise_p: 0.0770621105843944\n",
      "23500  | d_loss: 0.437501719892  | g_loss: 1.68783170819  | noise_p: 0.07629532977243969\n",
      "23600  | d_loss: 0.454958016872  | g_loss: 1.63959870219  | noise_p: 0.07553617855704185\n",
      "23700  | d_loss: 0.439323725998  | g_loss: 1.59686490059  | noise_p: 0.07478458102244677\n",
      "23800  | d_loss: 0.433561919928  | g_loss: 1.76472400665  | noise_p: 0.07404046200827463\n",
      "23900  | d_loss: 0.435634379685  | g_loss: 1.69423315465  | noise_p: 0.07330374710200387\n",
      "24000  | d_loss: 0.443523601294  | g_loss: 1.70129564047  | noise_p: 0.07257436263153001\n",
      "24100  | d_loss: 0.445277336836  | g_loss: 1.64827272773  | noise_p: 0.07185223565779811\n",
      "24200  | d_loss: 0.444955973923  | g_loss: 1.70122539759  | noise_p: 0.07113729396750908\n",
      "24300  | d_loss: 0.450543348789  | g_loss: 1.71513047934  | noise_p: 0.07042946606589805\n",
      "24400  | d_loss: 0.443486439288  | g_loss: 1.62133339882  | noise_p: 0.06972868116958504\n",
      "24500  | d_loss: 0.435348102748  | g_loss: 1.67608854055  | noise_p: 0.0690348691994964\n",
      "24600  | d_loss: 0.451932310164  | g_loss: 1.74194570065  | noise_p: 0.06834796077385699\n",
      "24700  | d_loss: 0.438396089375  | g_loss: 1.65962392092  | noise_p: 0.06766788720125176\n",
      "24800  | d_loss: 0.427482335567  | g_loss: 1.74093460679  | noise_p: 0.06699458047375677\n",
      "24900  | d_loss: 0.426941414177  | g_loss: 1.81043594122  | noise_p: 0.06632797326013813\n",
      "25000  | d_loss: 0.427574097812  | g_loss: 1.8442006743  | noise_p: 0.06566799889911905\n",
      "25100  | d_loss: 0.427636180818  | g_loss: 1.80696777463  | noise_p: 0.06501459139271334\n",
      "25200  | d_loss: 0.428947440982  | g_loss: 1.74424579501  | noise_p: 0.06436768539962595\n",
      "25300  | d_loss: 0.434776071906  | g_loss: 1.67127485156  | noise_p: 0.06372721622871841\n",
      "25400  | d_loss: 0.445456456244  | g_loss: 1.70272226095  | noise_p: 0.06309311983253996\n",
      "25500  | d_loss: 0.435895176828  | g_loss: 1.6849941206  | noise_p: 0.06246533280092251\n",
      "25600  | d_loss: 0.443343992233  | g_loss: 1.76966176569  | noise_p: 0.0618437923546398\n",
      "25700  | d_loss: 0.434185228944  | g_loss: 1.74626230121  | noise_p: 0.061228436339129194\n",
      "25800  | d_loss: 0.427715893388  | g_loss: 1.68479578137  | noise_p: 0.060619203218276387\n",
      "25900  | d_loss: 0.430196099281  | g_loss: 1.72056364417  | noise_p: 0.06001603206826155\n",
      "26000  | d_loss: 0.428760797381  | g_loss: 1.74496212244  | noise_p: 0.059418862571467106\n",
      "26100  | d_loss: 0.437368060052  | g_loss: 1.73044537306  | noise_p: 0.05882763501044566\n",
      "26200  | d_loss: 0.430253703892  | g_loss: 1.71437139988  | noise_p: 0.05824229026194847\n",
      "26300  | d_loss: 0.425435521007  | g_loss: 1.79609883785  | noise_p: 0.05766276979101286\n",
      "26400  | d_loss: 0.420491173863  | g_loss: 1.79232970357  | noise_p: 0.05708901564510885\n",
      "26500  | d_loss: 0.408966136873  | g_loss: 1.91791924238  | noise_p: 0.05652097044834368\n",
      "26600  | d_loss: 0.429719145  | g_loss: 1.7764040494  | noise_p: 0.05595857739572429\n",
      "26700  | d_loss: 0.424676240981  | g_loss: 1.80286222816  | noise_p: 0.0554017802474768\n",
      "26800  | d_loss: 0.423283903003  | g_loss: 1.81758747339  | noise_p: 0.05485052332342233\n",
      "26900  | d_loss: 0.419931344688  | g_loss: 1.78977979422  | noise_p: 0.054304751497409154\n",
      "27000  | d_loss: 0.415919598937  | g_loss: 1.78726501107  | noise_p: 0.05376441019179981\n",
      "27100  | d_loss: 0.405151367784  | g_loss: 1.92848479867  | noise_p: 0.05322944537201349\n",
      "27200  | d_loss: 0.422106023729  | g_loss: 1.84729607344  | noise_p: 0.05269980354112236\n",
      "27300  | d_loss: 0.435504814684  | g_loss: 1.75093047142  | noise_p: 0.05217543173450202\n",
      "27400  | d_loss: 0.432237940431  | g_loss: 1.81669410706  | noise_p: 0.051656277514534776\n",
      "27500  | d_loss: 0.426465817988  | g_loss: 1.74941367626  | noise_p: 0.05114228896536606\n",
      "27600  | d_loss: 0.432464533746  | g_loss: 1.78047046065  | noise_p: 0.05063341468771257\n",
      "27700  | d_loss: 0.426129111648  | g_loss: 1.84050035834  | noise_p: 0.05012960379372253\n",
      "27800  | d_loss: 0.422383132875  | g_loss: 1.82045849085  | noise_p: 0.049630805901886635\n",
      "27900  | d_loss: 0.419833427966  | g_loss: 1.74528207064  | noise_p: 0.04913697113200011\n",
      "28000  | d_loss: 0.422400568724  | g_loss: 1.76628322363  | noise_p: 0.04864805010017437\n",
      "28100  | d_loss: 0.422907762527  | g_loss: 1.74697576284  | noise_p: 0.048163993913898834\n",
      "28200  | d_loss: 0.421925261617  | g_loss: 1.85363797665  | noise_p: 0.047684754167151476\n",
      "28300  | d_loss: 0.418459030092  | g_loss: 1.80470617533  | noise_p: 0.047210282935558276\n",
      "28400  | d_loss: 0.412045961916  | g_loss: 1.82619588137  | noise_p: 0.046740532771600646\n",
      "28500  | d_loss: 0.425400030017  | g_loss: 1.79210948229  | noise_p: 0.046275456699870765\n",
      "28600  | d_loss: 0.424382626712  | g_loss: 1.81169240713  | noise_p: 0.045815008212373866\n",
      "28700  | d_loss: 0.424546085894  | g_loss: 1.81671571493  | noise_p: 0.04535914126387752\n",
      "28800  | d_loss: 0.417344378233  | g_loss: 1.82371235728  | noise_p: 0.04490781026730697\n",
      "28900  | d_loss: 0.432772988677  | g_loss: 1.7377639246  | noise_p: 0.04446097008918645\n",
      "29000  | d_loss: 0.418009326458  | g_loss: 1.78623900771  | noise_p: 0.04401857604512577\n",
      "29100  | d_loss: 0.40514239341  | g_loss: 1.792612499  | noise_p: 0.04358058389535189\n",
      "29200  | d_loss: 0.411510926485  | g_loss: 1.7701653862  | noise_p: 0.04314694984028482\n",
      "29300  | d_loss: 0.412778390348  | g_loss: 1.8104028523  | noise_p: 0.04271763051615767\n",
      "29400  | d_loss: 0.41782728374  | g_loss: 1.86468850136  | noise_p: 0.0422925829906803\n",
      "29500  | d_loss: 0.418550685644  | g_loss: 1.84131023645  | noise_p: 0.041871764758745905\n",
      "29600  | d_loss: 0.417222565711  | g_loss: 1.81129647374  | noise_p: 0.04145513373818067\n",
      "29700  | d_loss: 0.418505733311  | g_loss: 1.85521427393  | noise_p: 0.04104264826553529\n",
      "29800  | d_loss: 0.435392390192  | g_loss: 1.75680792332  | noise_p: 0.04063426709191881\n",
      "29900  | d_loss: 0.418788690269  | g_loss: 1.74811230779  | noise_p: 0.040229949378873496\n",
      "30000  | d_loss: 0.421088217497  | g_loss: 1.76063292623  | noise_p: 0.03982965469429116\n",
      "30100  | d_loss: 0.422167938054  | g_loss: 1.73124872684  | noise_p: 0.039433343008369724\n",
      "30200  | d_loss: 0.418369056582  | g_loss: 1.76109706521  | noise_p: 0.039040974689610375\n",
      "30300  | d_loss: 0.420479003787  | g_loss: 1.78960926533  | noise_p: 0.03865251050085422\n",
      "30400  | d_loss: 0.43302479744  | g_loss: 1.78436973572  | noise_p: 0.038267911595358695\n",
      "30500  | d_loss: 0.420236400664  | g_loss: 1.77558889747  | noise_p: 0.037887139512912726\n",
      "30600  | d_loss: 0.425015489459  | g_loss: 1.77702368021  | noise_p: 0.037510156175990794\n",
      "30700  | d_loss: 0.442042080462  | g_loss: 1.7520532465  | noise_p: 0.037136923885945\n",
      "30800  | d_loss: 0.420532252491  | g_loss: 1.74891693592  | noise_p: 0.03676740531923536\n",
      "30900  | d_loss: 0.411297911108  | g_loss: 1.80510021806  | noise_p: 0.03640156352369724\n",
      "31000  | d_loss: 0.415391131043  | g_loss: 1.79868780255  | noise_p: 0.03603936191484624\n",
      "31100  | d_loss: 0.431366726458  | g_loss: 1.76505635858  | noise_p: 0.03568076427221961\n",
      "31200  | d_loss: 0.412456390858  | g_loss: 1.83816577435  | noise_p: 0.03532573473575429\n",
      "31300  | d_loss: 0.43310580641  | g_loss: 1.78374499321  | noise_p: 0.034974237802200735\n",
      "31400  | d_loss: 0.426233231127  | g_loss: 1.75867296815  | noise_p: 0.034626238321572717\n",
      "31500  | d_loss: 0.409101676643  | g_loss: 1.7797294122  | noise_p: 0.03428170149363213\n",
      "31600  | d_loss: 0.402021635771  | g_loss: 1.80264618754  | noise_p: 0.03394059286440911\n",
      "31700  | d_loss: 0.421676344573  | g_loss: 1.76610182881  | noise_p: 0.03360287832275643\n",
      "31800  | d_loss: 0.410062474608  | g_loss: 1.84410105109  | noise_p: 0.03326852409693853\n",
      "31900  | d_loss: 0.411789684594  | g_loss: 1.80447156549  | noise_p: 0.032937496751254194\n",
      "32000  | d_loss: 0.424696598053  | g_loss: 1.83474311709  | noise_p: 0.03260976318269297\n",
      "32100  | d_loss: 0.406259278357  | g_loss: 1.79208756685  | noise_p: 0.03228529061762492\n",
      "32200  | d_loss: 0.404802215695  | g_loss: 1.78543385386  | noise_p: 0.03196404660852312\n",
      "32300  | d_loss: 0.416554825306  | g_loss: 1.83364961982  | noise_p: 0.031645999030718984\n",
      "32400  | d_loss: 0.406670402884  | g_loss: 1.86147613406  | noise_p: 0.031331116079189654\n",
      "32500  | d_loss: 0.399865366817  | g_loss: 1.85601848125  | noise_p: 0.03101936626537761\n",
      "32600  | d_loss: 0.391082009375  | g_loss: 1.86577555537  | noise_p: 0.030710718414041646\n",
      "32700  | d_loss: 0.396955899298  | g_loss: 1.91162342787  | noise_p: 0.030405141660139454\n",
      "32800  | d_loss: 0.400522958338  | g_loss: 1.8378029561  | noise_p: 0.030102605445740963\n",
      "32900  | d_loss: 0.399633862078  | g_loss: 1.90095602512  | noise_p: 0.02980307951697265\n",
      "33000  | d_loss: 0.403886134028  | g_loss: 1.88144165993  | noise_p: 0.029506533920991996\n",
      "33100  | d_loss: 0.41278465867  | g_loss: 1.86083449006  | noise_p: 0.029212939002992322\n",
      "33200  | d_loss: 0.39924837023  | g_loss: 1.86462698936  | noise_p: 0.02892226540323713\n",
      "33300  | d_loss: 0.409285856187  | g_loss: 1.83316615224  | noise_p: 0.028634484054124238\n",
      "33400  | d_loss: 0.405468769073  | g_loss: 1.83066190124  | noise_p: 0.028349566177278903\n",
      "33500  | d_loss: 0.403894942999  | g_loss: 1.81359544396  | noise_p: 0.02806748328067602\n",
      "33600  | d_loss: 0.396479639709  | g_loss: 1.84050403714  | noise_p: 0.02778820715579084\n",
      "33700  | d_loss: 0.40106246084  | g_loss: 1.88814593434  | noise_p: 0.02751170987477817\n",
      "33800  | d_loss: 0.399992083311  | g_loss: 1.82386749506  | noise_p: 0.027237963787679467\n",
      "33900  | d_loss: 0.417027163208  | g_loss: 1.83884341836  | noise_p: 0.02696694151965792\n",
      "34000  | d_loss: 0.410077823997  | g_loss: 1.81845569134  | noise_p: 0.026698615968260855\n",
      "34100  | d_loss: 0.40116402328  | g_loss: 1.85585078716  | noise_p: 0.026432960300709546\n",
      "34200  | d_loss: 0.406971775591  | g_loss: 1.8487930727  | noise_p: 0.02616994795121584\n",
      "34300  | d_loss: 0.410572570562  | g_loss: 1.79065944552  | noise_p: 0.025909552618325633\n",
      "34400  | d_loss: 0.407914900184  | g_loss: 1.80075462341  | noise_p: 0.025651748262288616\n",
      "34500  | d_loss: 0.398913610578  | g_loss: 1.82074456096  | noise_p: 0.02539650910245435\n",
      "34600  | d_loss: 0.413195261061  | g_loss: 1.80777539968  | noise_p: 0.02514380961469417\n",
      "34700  | d_loss: 0.416233492792  | g_loss: 1.78834068656  | noise_p: 0.02489362452884869\n",
      "34800  | d_loss: 0.403382704556  | g_loss: 1.79345365167  | noise_p: 0.024645928826200862\n",
      "34900  | d_loss: 0.404617766142  | g_loss: 1.83062986135  | noise_p: 0.024400697736973988\n",
      "35000  | d_loss: 0.403551496565  | g_loss: 1.83001179338  | noise_p: 0.0241579067378548\n",
      "35100  | d_loss: 0.402262567282  | g_loss: 1.85923265815  | noise_p: 0.023917531549541047\n",
      "35200  | d_loss: 0.398705188036  | g_loss: 1.8800216198  | noise_p: 0.0236795481343136\n",
      "35300  | d_loss: 0.407180216014  | g_loss: 1.85465570807  | noise_p: 0.023443932693632596\n",
      "35400  | d_loss: 0.39581291914  | g_loss: 1.8408805716  | noise_p: 0.023210661665757644\n",
      "35500  | d_loss: 0.393462884426  | g_loss: 1.85650214195  | noise_p: 0.02297971172339154\n",
      "35600  | d_loss: 0.396696361899  | g_loss: 1.84271707892  | noise_p: 0.022751059771347604\n",
      "35700  | d_loss: 0.40152459085  | g_loss: 1.81454621553  | noise_p: 0.02252468294424008\n",
      "35800  | d_loss: 0.394688809812  | g_loss: 1.85524329424  | noise_p: 0.022300558604197614\n",
      "35900  | d_loss: 0.394978396893  | g_loss: 1.85081691146  | noise_p: 0.022078664338599424\n",
      "36000  | d_loss: 0.401364369392  | g_loss: 1.87185115099  | noise_p: 0.02185897795783405\n",
      "36100  | d_loss: 0.40063067317  | g_loss: 1.85877722502  | noise_p: 0.021641477493080322\n",
      "36200  | d_loss: 0.406538753211  | g_loss: 1.85276384711  | noise_p: 0.021426141194110543\n",
      "36300  | d_loss: 0.39681788981  | g_loss: 1.84856862426  | noise_p: 0.021212947527115337\n",
      "36400  | d_loss: 0.408297323287  | g_loss: 1.79353247523  | noise_p: 0.02100187517255037\n",
      "36500  | d_loss: 0.399021245539  | g_loss: 1.81498868585  | noise_p: 0.020792903023004267\n",
      "36600  | d_loss: 0.398209694326  | g_loss: 1.82832061172  | noise_p: 0.020586010181087952\n",
      "36700  | d_loss: 0.394045853615  | g_loss: 1.83637449861  | noise_p: 0.020381175957344805\n",
      "36800  | d_loss: 0.391629799306  | g_loss: 1.88300026298  | noise_p: 0.020178379868181773\n",
      "36900  | d_loss: 0.397710788846  | g_loss: 1.86709477663  | noise_p: 0.019977601633820917\n",
      "37000  | d_loss: 0.402723380029  | g_loss: 1.8589738667  | noise_p: 0.019778821176271513\n",
      "37100  | d_loss: 0.394587863982  | g_loss: 1.8572697401  | noise_p: 0.019582018617322137\n",
      "37200  | d_loss: 0.389041770101  | g_loss: 1.83772185802  | noise_p: 0.019387174276552892\n",
      "37300  | d_loss: 0.39645694375  | g_loss: 1.8412882638  | noise_p: 0.01919426866936734\n",
      "37400  | d_loss: 0.397455396652  | g_loss: 1.82216848969  | noise_p: 0.019003282505044\n",
      "37500  | d_loss: 0.392800923586  | g_loss: 1.80774944186  | noise_p: 0.018814196684807286\n",
      "37600  | d_loss: 0.391501267254  | g_loss: 1.81960174918  | noise_p: 0.0186269922999176\n",
      "37700  | d_loss: 0.396459949017  | g_loss: 1.87260461807  | noise_p: 0.018441650629780457\n",
      "37800  | d_loss: 0.394750508368  | g_loss: 1.89689693213  | noise_p: 0.01825815314007438\n",
      "37900  | d_loss: 0.392190878987  | g_loss: 1.87172343493  | noise_p: 0.01807648148089749\n",
      "38000  | d_loss: 0.39713460505  | g_loss: 1.88789773583  | noise_p: 0.017896617484932473\n",
      "38100  | d_loss: 0.403086648881  | g_loss: 1.86962169766  | noise_p: 0.017718543165629853\n",
      "38200  | d_loss: 0.400971117914  | g_loss: 1.88072680235  | noise_p: 0.017542240715409288\n",
      "38300  | d_loss: 0.398413154483  | g_loss: 1.86589292407  | noise_p: 0.017367692503878856\n",
      "38400  | d_loss: 0.385360074639  | g_loss: 1.86368709087  | noise_p: 0.017194881076071932\n",
      "38500  | d_loss: 0.385139086246  | g_loss: 1.92861875057  | noise_p: 0.017023789150701737\n",
      "38600  | d_loss: 0.37980748713  | g_loss: 1.90681820512  | noise_p: 0.01685439961843314\n",
      "38700  | d_loss: 0.384327085912  | g_loss: 1.91726902008  | noise_p: 0.016686695540171773\n",
      "38800  | d_loss: 0.388507184684  | g_loss: 1.88737038732  | noise_p: 0.016520660145370045\n",
      "38900  | d_loss: 0.383465813696  | g_loss: 1.85292269945  | noise_p: 0.01635627683035012\n",
      "39000  | d_loss: 0.385264889896  | g_loss: 1.86989296794  | noise_p: 0.016193529156643505\n",
      "39100  | d_loss: 0.396322534978  | g_loss: 1.85820875525  | noise_p: 0.016032400849347213\n",
      "39200  | d_loss: 0.395942046046  | g_loss: 1.85304914713  | noise_p: 0.015872875795496226\n",
      "39300  | d_loss: 0.403985152841  | g_loss: 1.84382480621  | noise_p: 0.015714938042452234\n",
      "39400  | d_loss: 0.39069199115  | g_loss: 1.83407010913  | noise_p: 0.015558571796308308\n",
      "39500  | d_loss: 0.395963099003  | g_loss: 1.86689314604  | noise_p: 0.015403761420309537\n",
      "39600  | d_loss: 0.392301667333  | g_loss: 1.88542914152  | noise_p: 0.015250491433289302\n",
      "39700  | d_loss: 0.380140369833  | g_loss: 1.88523897529  | noise_p: 0.015098746508121189\n",
      "39800  | d_loss: 0.385374323726  | g_loss: 1.90159066319  | noise_p: 0.01494851147018622\n",
      "39900  | d_loss: 0.380303569138  | g_loss: 1.91788102269  | noise_p: 0.014799771295855394\n"
     ]
    }
   ],
   "source": [
    "num_steps = 40000 #2000\n",
    "k_steps = 1\n",
    "n_logging = 100\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "print('Initialized')\n",
    "\n",
    "\n",
    "g_loss= 0\n",
    "d_loss= 0\n",
    "for step in range(num_steps):\n",
    "    # ------- optimize discriminator -------\n",
    "    for k in range(k_steps):\n",
    "        # get samples from the generator\n",
    "        batch_z = random_generator(m, z_size)\n",
    "        [batch_gz] = sess.run([gen_model], feed_dict= {g_traind.inputs : batch_z, drop_prob_g : 1.0})\n",
    "        \n",
    "        # get samples from data\n",
    "        noise_p = 0.8*math.exp(-0.0001*step); # noise percentage\n",
    "        batch_x = data_generator(m, noise_p)\n",
    "        \n",
    "        # concatenate samples\n",
    "        batch_x_z= np.concatenate((batch_x, batch_gz), axis=0)\n",
    "        batch_y= np.concatenate((np.ones((m,1)), np.zeros((m,1))), axis=0)        \n",
    "        \n",
    "        # run gradient descent to train the discriminator\n",
    "        feed_dict = {d_traind.inputs : batch_x_z, d_traind.labels : batch_y, drop_prob_d : 1.0}\n",
    "        \n",
    "        _, l = sess.run([d_optimizer, traind_loss],feed_dict=feed_dict)\n",
    "        d_loss += l\n",
    "    \n",
    "    # ------- optimize generator --------\n",
    "    \n",
    "    # get noise samples\n",
    "    batch_z = random_generator(m, z_size)\n",
    "    \n",
    "    # run gradient descent to train the generator\n",
    "    feed_dict = {g_traing.inputs: batch_z, d_traing.labels: np.ones((m,1)), drop_prob_d: 1.0, drop_prob_g: 1.0}\n",
    "    \n",
    "    _, l = sess.run([g_optimizer, traing_loss],feed_dict=feed_dict)        \n",
    "        \n",
    "    g_loss += l\n",
    "    \n",
    "    #  ------- logging -------\n",
    "    \n",
    "    if step%n_logging == 0:\n",
    "        print( step, ' | d_loss:', d_loss/(n_logging*k_steps), ' | g_loss:', g_loss/n_logging, ' | noise_p:', noise_p )\n",
    "        d_loss = 0\n",
    "        g_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate some samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999995288\n",
      "2.94751743203e-08\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f90f9c84eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# real\n",
    "noise_p = 0.7*math.exp(-0.0001*num_steps*1.0);\n",
    "batch_x = data_generator(m, noise_p)\n",
    "batch_x = np.reshape(batch_x, [-1,28,28,1])\n",
    "\n",
    "print(np.max(batch_x))\n",
    "print(np.min(batch_x))\n",
    "\n",
    "imgplot = plt.imshow(batch_x[1,:,:,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generated\n",
    "batch_z = batch_z = random_generator(m, z_size)\n",
    "[batch_gz] = sess.run([gen_model], feed_dict= {g_traind.inputs : batch_z})\n",
    "#[batch_gz] = sess.run([g_traind.y], feed_dict= {g_traind.inputs : batch_z})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 784)\n"
     ]
    }
   ],
   "source": [
    "#print(batch_z[1,:])\n",
    "#print(batch_z[30,:])\n",
    "#print('--------------')\n",
    "#print(batch_gz[1,:])\n",
    "#print(batch_gz[30,:])\n",
    "\n",
    "\n",
    "print(batch_gz.shape)\n",
    "idx= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f90fe8b20b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_gz = np.reshape(batch_gz, [-1,28,28,1])\n",
    "\n",
    "#print(batch_gz[0,:,:,0])\n",
    "imgplot = plt.imshow(batch_gz[idx,:,:,0]-batch_gz[idx+1,:,:,0])\n",
    "idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEoVJREFUeJzt3WuMXOV5B/D/M+P1be2AL9SywYWUOlDLSgzaOpViRUkD\nlKCoJvlA4w+pqRCOKlCbKh+K3Ki1+olekgipUSQnuDFVQlI1ICyVXIihpWkji7Xj+Bpih5rarm/U\nt/Vl196Zpx/2QBbY8zyz857LrJ7/T7J2d94557x7Zv6e2Xne876iqiCieBp1d4CI6sHwEwXF8BMF\nxfATBcXwEwXF8BMFxfATBcXwEwXF8BMFNa3Kg02XGToT/eXsXMRu90Yypm7fo8T5vbwRntJs2tu3\nWk4HrI3tTcuU/ns5zxfvlyvpdx/GJVzVEa9zABLDLyL3AngCQBPA11X1cev+M9GPDzbv6f6A7fwH\nRPqmm5vqtatmu7v96DWjMfGRbNhPROv3dnc9c6a96+Fhs735nuvM9ta582a7TMt/iunoqLltmZrX\nzTPbW+fOme0y3X6+wPnPo6zffbtu6/i+Xb/tF5EmgK8A+DiA5QDWisjybvdHRNVK+Zt/FYBDqvqa\nql4F8G0Aa4rpFhGVLSX8NwI4Mu7no9ltbyMi60VkUEQGr2Ek4XBEVKTSP+1X1U2qOqCqA32YUfbh\niKhDKeE/BmDpuJ9vym4joikgJfyvAFgmIu8VkekAPg1gazHdIqKydV3qU9VREXkUwA8wVurbrKr7\n3A0TylZmf1JLec72ZjnOq6p6v7O2zWaZYf+5pFfz++6V8jxeKc9TZznP4pXyPNY570SjP3+8S/vS\nJXtja4zBJKrOSXV+VX0ewPMp+yCienB4L1FQDD9RUAw/UVAMP1FQDD9RUAw/UVCVXs9fKueyWPOS\n3A5In3Fp6kjiNQvOJcHNhQvM9tFj/5vfmDhPgTc+QmbaYxDaly4bx7bHNyRfKm3Ww9P2nTpuxKzl\nVzS3BF/5iYJi+ImCYviJgmL4iYJi+ImCYviJgqq01CeNBhqzEy5ltHhlo0RWOa/Uy4UBtC8Mme3N\nBfNz21r/d8Y+tje1t1Mi1aG0S1tLZZXEEstp7mOaQKb1VXJsvvITBcXwEwXF8BMFxfATBcXwEwXF\n8BMFxfATBVVpnV/b7bRavqExa5bZ3r5ypZTjAul1/OatN5vtrYOvTbZLHfvLX+4w25vOXNBfeOhh\ne/uXdk66T0WxVij2pjS3VhcG/FV628POZd7GdO5J09Bf62h1bgB85ScKi+EnCorhJwqK4ScKiuEn\nCorhJwqK4ScKKqnOLyKHAQwBaAEYVdWBIjqVy6iXty8bU0Qn7nvsAAlLizvbllnH9+rVPxpaYbb/\n3tw9Zvu5W+2puxe8ZDaXKmV5cm9pcW3b4x8a0+1r8tsj+fNPeNfzNxfmz98gp53n8ThFDPL5qKq+\nUcB+iKhCfNtPFFRq+BXAD0Vkh4isL6JDRFSN1Lf9q1X1mIj8GoAXROTnqvry+Dtk/ymsB4CZmJ14\nOCIqStIrv6oey76eAvAsgFUT3GeTqg6o6kAf7A+HiKg6XYdfRPpFZO6b3wO4B8DeojpGROVKedu/\nCMCzMjYF8jQA31LV7xfSKyIqXdfhV9XXAHygwL74UmrtqbxxAJYa+60t+9jP/Lf9EH7ht+03c3c8\nvNts/5+vm81Tl/OYtoedx9xYN8C7nr/1Rv5aDDra+XONpT6ioBh+oqAYfqKgGH6ioBh+oqAYfqKg\nKp26GyLmtMNlLnvsKrEcd3DLnWb7sgd/au/AWS46xbdWbnbuYY/KfPCG/zDb/xr2714qaxnuEs+p\ne2zn+DLDPufWcvGT+b34yk8UFMNPFBTDTxQUw08UFMNPFBTDTxQUw08UVLV1ftV6a/k1WbYubZnq\n5rx5Znvr7Nn8RrH/f/+TQ39gtm9bvtVs/5sj95rtaJzObyv5UmdrCuzU52HSY+LQq9VkhK/8REEx\n/ERBMfxEQTH8REEx/ERBMfxEQTH8REFVfD2/vWS0tyxyrddn1yilZuzV0i/94xJ7+7+zm/e+bm+/\nrH3C3kGJdPRaaftOekw83nPZzEHnh+ErP1FQDD9RUAw/UVAMP1FQDD9RUAw/UVAMP1FQbp1fRDYD\n+ASAU6q6IrttPoDvALgFwGEAD6hqB4VPca8vp2rNPmnXwi+2h832u28/YLYfnmyHJsOZG78xZ05u\nW3toqOjeFCdhzv/J6CSJ3wDwzhkbHgOwTVWXAdiW/UxEU4gbflV9GcCZd9y8BsCW7PstAO4vuF9E\nVLJu34MvUtXj2fcnACwqqD9EVJHksf2qqiKS+0eIiKwHsB4AZmJ26uGIqCDdvvKfFJHFAJB9PZV3\nR1XdpKoDqjrQJzO7PBwRFa3b8G8FsC77fh2A54rpDhFVxQ2/iDwN4CcAbhORoyLyEIDHAdwtIgcB\n3JX9TERTiPs3v6quzWn62KSP5s3bX2Z9s8R9u3O4nztX2rGTNezzMqdh/6l2eGiB2S7T8q/nd+dv\n8DjnrdFvfMbUsuc5aF++3E2PfsV7vlnjXbz1DBrN/LZJLIXAETdEQTH8REEx/ERBMfxEQTH8REEx\n/ERBVTt1tydlyuLUfTukb3p+4+Ib7I2daZ6t6cyBAkpihsO/b5SNOvDIr79otn+l/VtJ+08xeuJk\nbcd2n29a7vLkneArP1FQDD9RUAw/UVAMP1FQDD9RUAw/UVAMP1FQvVXn9yTU6mXGDHvXIyN2u7Hc\nc2v/L7rq06/2XV4d3xtDcN1+p87/Kbv5z/71D832ZY3B3DZt2/uulXXZLOBfdutJWW4+9dgZvvIT\nBcXwEwXF8BMFxfATBcXwEwXF8BMFxfATBTW16vwJvDq+v4Pyptcu83p+b9uh1YlTVHuXrZc4hiFJ\nytwQRTCeT97zwTSJ081XfqKgGH6ioBh+oqAYfqKgGH6ioBh+oqAYfqKg3IKiiGwG8AkAp1R1RXbb\nRgAPAzid3W2Dqj5fVic74l1/7V08XuMy2aXWwp169our/8HZwRyzdfq5Kfr64T7e9vOlzrEZ9sad\n37WTR+4bAO6d4PYvq+rK7F+9wSeiSXPDr6ovAzhTQV+IqEIp79keFZHdIrJZROYV1iMiqkS34f8q\ngFsBrARwHMAX8+4oIutFZFBEBq8hcXw9ERWmq/Cr6klVbalqG8DXAKwy7rtJVQdUdaAP9iSaRFSd\nrsIvIovH/fhJAHuL6Q4RVaWTUt/TAD4CYKGIHAXwVwA+IiIrMVZYOAzgsyX2kYhK4IZfVddOcPOT\nXR8xZb5ySw/X8V1OLb453/48tXXmbP6um/b4h7mSVqdv5C9nUD7vmnzjd/POi7VOA+DX+WXWLLO9\nffGi2W4q6Lk8RUdoEFEqhp8oKIafKCiGnygohp8oKIafKKjqp+62yhRe6cbatpdLeR6n7zrsDIs2\ntm/M6e+mR29pOSXUG35aX62v4Sy73h4ezm3TxGWutWWfFx1xSnlWidXrm1kutzcdj6/8REEx/ERB\nMfxEQTH8REEx/ERBMfxEQTH8REH11hLdU7lWX6LRO99ntjd/sie37fzdt5vbtmBPvPxvw31me//+\nE2Z7mQt0W3V8V8qYEgCNfvuS3dZ5Z/yDdwm6uS0v6SWiBAw/UVAMP1FQDD9RUAw/UVAMP1FQDD9R\nUNXW+cWe8lhbCddY9/IYgdSa8n/utjc32lZv2G5uO7cx3Wxf0hwy29tnzpntPcs559Jnn5fW+Qul\nHb+xwh6b0d7787Rjv3mcQvZCRFMOw08UFMNPFBTDTxQUw08UFMNPFBTDTxSUW+cXkaUAngKwCGMl\n5U2q+oSIzAfwHQC3ADgM4AFVzV8rGsDIzbPx6sYP5La/7492dNzxSUustSdJ3bczj7sY89e/MWJf\nd+7ZOpT/eAGALFlk7+BVe5xAbZzng167am/fsJf4dg8/LX/7our4nk5e+UcBfF5VlwP4HQCPiMhy\nAI8B2KaqywBsy34moinCDb+qHlfVndn3QwAOALgRwBoAW7K7bQFwf1mdJKLiTepvfhG5BcAdALYD\nWKSqx7OmExj7s4CIpoiOwy8icwB8F8DnVPVtA5tVVZEzxFxE1ovIoIgMtoYuJXWWiIrTUfhFpA9j\nwf+mqj6T3XxSRBZn7YsBnJpoW1XdpKoDqjrQnJu2aCQRFccNv4gIgCcBHFDVL41r2gpgXfb9OgDP\nFd89IipLJ5f0fgjAZwDsEZFd2W0bADwO4J9F5CEArwN4wNvRzNev4PY/3pfbnjCZMRqzZ5vt7StX\nEvbe2xrXX5fb9l9H7I9iTi/5vtn+4qnb7GMfPW62J6mzPOse23m2esuup0zdXRA3/Kr6YwB5Z+Jj\nxXaHiKrCEX5EQTH8REEx/ERBMfxEQTH8REEx/ERBVTp1t6rayyon1HXbly+bm1pThgOAtp2asXNZ\nbamc8yKz8y/b/fDNh8xtf3DpN8329887ZrbvhT2+wuy7V6ev8TLrRr89GtV7viWNUfC2FeM1exJP\nU77yEwXF8BMFxfATBcXwEwXF8BMFxfATBcXwEwVV7RLdiRorl+e2tXftN7fV0dGkYyctLZ5Yr27M\nsqffPnnXkty2DQufNbfdN3KT2f4vgwNm+21Xf2a29+zS6U4tvX3JnnLOmi4dAPSqPfW3Nf+EO/dE\nQWNO+MpPFBTDTxQUw08UFMNPFBTDTxQUw08UFMNPFJRohXXY98h8/WDjrtz25ty55vatCxfM9iR1\nzhHvaDjnRYdHjEZ7fnhvjELz+uvN9tZ55zGpcx4Ei7fEdtn9TpnnwLBdt+GCnnGezGP4yk8UFMNP\nFBTDTxQUw08UFMNPFBTDTxQUw08UlHs9v4gsBfAUgEUAFMAmVX1CRDYCeBjA6eyuG1T1efeIxpzj\nrYv2NdRmbdSayxxIXk+9TK2P3mnf4aWd1XRkAq2zZ9N2YNTTpc9ZS2HEGL8A+GMzDI3pfWZ7ezix\nzp8ybqSiMQidTOYxCuDzqrpTROYC2CEiL2RtX1bVvy+kJ0RUKTf8qnocwPHs+yEROQDgxrI7RkTl\nmtTf/CJyC4A7AGzPbnpURHaLyGYRmZezzXoRGRSRwWtw3sYRUWU6Dr+IzAHwXQCfU9ULAL4K4FYA\nKzH2zuCLE22nqptUdUBVB/pgz3tGRNXpKPwi0oex4H9TVZ8BAFU9qaotVW0D+BqAVeV1k4iK5oZf\nRATAkwAOqOqXxt2+eNzdPglgb/HdI6KydPJp/4cAfAbAHhHZld22AcBaEVmJsfLfYQCfTe5NSglD\nE8sfXnnFKBU2nGmczWXJATT/3Z7+2psmWoyykjtledP+vYd/9/1m+6wjQ2Z7e9+ruW16LW06dZe1\npLvzmJR5bJeXA+u5OokYdPJp/48BTPTs8mv6RNSzOMKPKCiGnygohp8oKIafKCiGnygohp8oqOqX\n6E6p5adMd+xcYikNu11HS7zk1zknOuK0p5wXZ+ruGd97xWx3LpS2pY7NSHnMvW1LvqzWXPLdG5vB\nJbqJKAXDTxQUw08UFMNPFBTDTxQUw08UFMNPFFSlS3SLyGkAr4+7aSGANyrrwOT0at96tV8A+9at\nIvt2s6re0MkdKw3/uw4uMqiqA7V1wNCrfevVfgHsW7fq6hvf9hMFxfATBVV3+DfVfHxLr/atV/sF\nsG/dqqVvtf7NT0T1qfuVn4hqUkv4ReReEXlVRA6JyGN19CGPiBwWkT0isktEBmvuy2YROSUie8fd\nNl9EXhCRg9nXCZdJq6lvG0XkWHbudonIfTX1bamIvCQi+0Vkn4j8aXZ7refO6Fct563yt/0i0gTw\nCwB3AzgK4BUAa1V1f6UdySEihwEMqGrtNWER+TCAiwCeUtUV2W1/C+CMqj6e/cc5T1X/vEf6thHA\nxbpXbs4WlFk8fmVpAPcDeBA1njujXw+ghvNWxyv/KgCHVPU1Vb0K4NsA1tTQj56nqi8DOPOOm9cA\n2JJ9vwVjT57K5fStJ6jqcVXdmX0/BODNlaVrPXdGv2pRR/hvBHBk3M9H0VtLfiuAH4rIDhFZX3dn\nJrAoWzYdAE4AWFRnZybgrtxcpXesLN0z566bFa+Lxg/83m21qt4J4OMAHsne3vYkHfubrZfKNR2t\n3FyVCVaWfkud567bFa+LVkf4jwFYOu7nm7LbeoKqHsu+ngLwLHpv9eGTby6Smn09VXN/3tJLKzdP\ntLI0euDc9dKK13WE/xUAy0TkvSIyHcCnAWytoR/vIiL92QcxEJF+APeg91Yf3gpgXfb9OgDP1diX\nt+mVlZvzVpZGzeeu51a8VtXK/wG4D2Of+P8SwF/U0Yecfv0GgJ9l//bV3TcAT2PsbeA1jH028hCA\nBQC2ATgI4EcA5vdQ3/4JwB4AuzEWtMU19W01xt7S7wawK/t3X93nzuhXLeeNI/yIguIHfkRBMfxE\nQTH8REEx/ERBMfxEQTH8REEx/ERBMfxEQf0/4HRbS89HVrIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f90fcee6b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgplot = plt.imshow(batch_gz[idx,:,:,0])\n",
    "idx = idx+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
